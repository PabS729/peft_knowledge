2024-03-18 13:15:14.811565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/cluster/project/sachan/minjing/peft_knowledge/lora_reverse_eval.py", line 7, in <module>
    tokenizer = AutoTokenizer.from_pretrained(model_ids[2])
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/project/sachan/minjing/peft_knowledge/peft_knowledge/lib64/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 853, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/project/sachan/minjing/peft_knowledge/peft_knowledge/lib64/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2070, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'mistralai/Mistral-7B-v0.1'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'mistralai/Mistral-7B-v0.1' is the correct path to a directory containing all relevant files for a LlamaTokenizerFast tokenizer.
